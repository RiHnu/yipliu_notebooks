{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobReturn(\n",
    "    overrides=['datamodule.batch_size=128', 'model.dropout=0.1', 'model.n_layers=2', 'model.hidden_dim=256'], \n",
    "    cfg={'experiment_name': 'Default', 'gpus': [0], 'lr': 0.001, 'weight_decay': 5e-05, 'batch_size': 64, 'epochs': 2, \n",
    "            'train_size': '${datamodule: train_size}', 'topk': 1, 'save_predictions': True, 'model_name': 'imdb', 'save_model': True, \n",
    "            'work_dir': '${hydra:runtime.cwd}', 'checkpoint_dir': '/mnt/HDD4/lyp/CheckPoints/fornlptest', 'data_dir': '${work_dir}/data', \n",
    "            'print_config': True, 'disable_warnings': True, 'disable_lightning_logs': False, \n",
    "            'trainer': {'_target_': 'pytorch_lightning.Trainer', 'gpus': '${gpus}', 'min_epochs': 1, \n",
    "            'max_epochs': '${epochs}', 'gradient_clip_val': 0.5, 'num_sanity_val_steps': 2, 'enable_model_summary': True, \n",
    "            'default_root_dir': '${checkpoint_dir}', 'fast_dev_run': False}, \n",
    "            'model': {'_target_': 'src.models.imdb_model.RNN', 'vocab_x_size': '${datamodule: vocab_x_size}', \n",
    "            'embedding_dim': 100, 'hidden_dim': 256, 'output_dim': '${datamodule: vocab_y_size}', 'n_layers': 2, 'bidirectional': True, 'dropout': 0.1, \n",
    "            'pad_idx': '${datamodule: pad_idx}'}, \n",
    "            'datamodule': {'_target_': 'src.datamodules.imdb_datamodule.IMDBDataModule', 'data_dir': '${data_dir}', \n",
    "                    'batch_size': 128, 'num_workers': 5, 'pin_memory': True, 'val_train_split_ratio': 0.5, \n",
    "                    'max_vocab_size': 25000, 'vocab_path': '${data_dir}/vocab', 'imdb_url': \n",
    "                    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz', 'MD5': '7c2ac02c03563afcf9b574c7e56c153a'}, \n",
    "            'optimizer': {'_target_': 'torch.optim.Adam', 'params': '???', 'lr': '${lr}', 'betas': [0.9, 0.999], \n",
    "                    'eps': 1e-08, 'weight_decay': '${weight_decay}', 'amsgrad': False}, \n",
    "        'scheduler': {'_target_': 'src.lr_scheduler.warmup_scheduler', 'optimizer': '???', 'steps_per_epoch': '???', \n",
    "                    'epochs': '${epochs}', 'warmup_ratio': 0.1}, \n",
    "        'logger': {'_target_': 'pytorch_lightning.loggers.MLFlowLogger', 'experiment_name': '${experiment_name}', 'tracking_uri': None, 'tags': None, 'save_dir': '${checkpoint_dir}/mlruns',\n",
    "                 'prefix': '', 'artifact_location': None}, \n",
    "        'callbacks': {'model_checkpoint': {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'monitor': 'val/acc', 'save_top_k': 2, \n",
    "                                    'save_last': True, 'mode': 'max', 'dirpath': 'checkpoints/', 'filename': '{epoch:02d}'}, \n",
    "                        'early_stopping': {'_target_': 'pytorch_lightning.callbacks.EarlyStopping', 'monitor': 'val/acc', 'patience': 100,\n",
    "                                             'mode': 'max', 'min_delta': 0.0}}, \n",
    "        'optimized_metric': 'val/acc'},\n",
    "     hydra_cfg={'hydra': {'run': {'dir': 'logs/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}'}, \n",
    "                'sweep': {'dir': 'logs/multiruns/${now:%Y-%m-%d_%H-%M-%S}', 'subdir': '${hydra.job.num}'}, \n",
    "                'launcher': {'_target_': 'hydra._internal.core_plugins.basic_launcher.BasicLauncher'}, \n",
    "                'sweeper': {'sampler': {'_target_': 'optuna.samplers.TPESampler', 'seed': 12345, 'consider_prior': True, \n",
    "                            'prior_weight': 1.0, 'consider_magic_clip': True, 'consider_endpoints': False, 'n_startup_trials': 10, \n",
    "                            'n_ei_candidates': 24, 'multivariate': False, 'warn_independent_sampling': True},\n",
    "                             '_target_': 'hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper', \n",
    "                             'direction': 'maximize', 'storage': None, 'study_name': None, 'n_trials': 20, 'n_jobs': 1, \n",
    "                            'search_space': {'datamodule.batch_size': {'type': 'categorical', 'choices': [32, 64, 128]}, \n",
    "                                                'model.dropout': {'type': 'categorical', 'choices': [0.05, 0.1, 0.25, 0.5]}, \n",
    "                                                'model.n_layers': {'type': 'categorical', 'choices': [1, 2]}, \n",
    "                                                'model.hidden_dim': {'type': 'categorical', 'choices': [128, 256]}}}, \n",
    "                    'help': {'app_name': '${hydra.job.name}', 'header': '${hydra.help.app_name} is powered by Hydra.\\n', \n",
    "                    'footer': 'Powered by Hydra (https://hydra.cc)\\nUse --hydra-help to view Hydra specific help\\n',\n",
    "                     'template': '${hydra.help.header}\\n== Configuration groups ==\\nCompose your configuration from those groups (group=option)\\n\\n $APP_CONFIG_GROUPS\\n\\n== Config ==\\nOverride anything in the config (foo.bar=value)\\n\\n$CONFIG\\n\\n${hydra.help.footer}\\n'}, \n",
    "                        'hydra_help': {'template': \"Hydra (${hydra.runtime.version})\\nSee https://hydra.cc for more info.\\n\\n== Flags ==\\n$FLAGS_HELP\\n\\n== Configuration groups ==\\nCompose your configuration from those groups (For example, append hydra/job_logging=disabled to command line)\\n\\n$HYDRA_CONFIG_GROUPS\\n\\nUse '--cfg hydra' to Show the Hydra config.\\n\", 'hydra_help': '???'}, \n",
    "                        'hydra_logging': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][HYDRA] %(message)s'}}, \n",
    "                            'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}}, \n",
    "                            'root': {'level': 'INFO', 'handlers': ['console']}, 'loggers': {'logging_example': {'level': 'DEBUG'}}, \n",
    "                            'disable_existing_loggers': False}, \n",
    "                        'job_logging': {'version': 1, 'formatters': \n",
    "                                        {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, \n",
    "                                        'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, \n",
    "                                                    'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '${hydra.job.name}.log'}}, \n",
    "                                        'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}, \n",
    "                'env': {}, 'searchpath': [], 'callbacks': {}, 'output_subdir': '.hydra', 'overrides': \n",
    "                        {'hydra': [], 'task': ['datamodule.batch_size=128', 'model.dropout=0.1', 'model.n_layers=2', 'model.hidden_dim=256']}, \n",
    "                'job': {'name': 'main', 'override_dirname': 'datamodule.batch_size=128,model.dropout=0.1,model.hidden_dim=256,model.n_layers=2', \n",
    "                        'id': '0', 'num': 0, 'config_name': 'config_optuna.yaml', 'env_set': {'WANDB_START_METHOD': 'thread'}, \n",
    "                            'env_copy': [], 'config': {'override_dirname': {'kv_sep': '=', 'item_sep': ',', 'exclude_keys': []}}}, \n",
    "                            'runtime': {'version': '1.1.0', 'cwd': '/home/lyp/team/personal_code/fornlptest', \n",
    "                            'config_sources': [{'path': 'hydra.conf', 'schema': 'pkg', 'provider': 'hydra'}, \n",
    "                            {'path': '/home/lyp/team/personal_code/fornlptest/configs', 'schema': 'file', 'provider': 'main'},\n",
    "                             {'path': 'hydra_plugins.hydra_colorlog.conf', 'schema': 'pkg', 'provider': 'hydra-colorlog'},\n",
    "                              {'path': '', 'schema': 'structured', 'provider': 'schema'}], \n",
    "                              'choices': {'hparams_search': 'imdb_optuna.yaml', 'callbacks': 'default.yaml', 'logger': 'mlflow.yaml', 'scheduler': 'warmup.yaml', 'optimizer': 'adam.yaml', 'datamodule': 'imdb_datamodule.yaml', 'model': 'imdb_model.yaml', 'trainer': 'default_trainer.yaml', 'hydra/env': 'default', \n",
    "                              'hydra/callbacks': None, 'hydra/job_logging': 'default', 'hydra/hydra_logging': 'default', 'hydra/hydra_help': 'default', 'hydra/help': 'default', 'hydra/sweeper': 'optuna', 'hydra/sweeper/sampler': 'tpe', 'hydra/launcher': 'basic', 'hydra/output': 'default'}}, 'verbose': False}}, \n",
    "        working_dir='logs/multiruns/2021-12-28_10-29-23/0', task_name='main', \n",
    "status=<JobStatus.COMPLETED: 1>, _return_value=None)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides = [('datamodule.batch_size=64', 'model.lr=0.05837132718621367', \n",
    "                'model.lin1_size=128', 'model.lin2_size=256', 'model.lin3_size=32', 'hparams_search=mnist_optuna')]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24e149ca21b7977f113f7cae485a610638989eae958e24203fa60c141501a44e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pylightnlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
