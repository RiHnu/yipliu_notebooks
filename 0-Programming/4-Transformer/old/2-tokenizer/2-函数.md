# tokenizer.padding_side   
> right or left
> Model 该从哪边进行 Pad

# tokenizer.add_special_tokens


# tokenizer.resize_token_embeddings(new_num_tokens)
> new_num_tokens: int
当给 tokenizer 增加 tokens 后，需要更新 embedding matrix 大小。一般是在 embedding matrix 的末尾进行 增加或者删除 Vector